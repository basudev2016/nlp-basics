{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11440602",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Artificial intelligence and machine learning are transforming industries.\",\n",
    "    \"Machine learning algorithms can analyze massive amounts of data quickly.\",\n",
    "    \"Deep learning allows machines to mimic human brain functions.\",\n",
    "    \"Natural language processing enables computers to understand human speech.\",\n",
    "    \"Data science combines domain expertise, programming, and statistics.\",\n",
    "    \"Big data analytics helps companies make better business decisions.\",\n",
    "    \"Neural networks are a foundation of modern AI applications.\",\n",
    "    \"Computer vision allows machines to interpret and understand images.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LDA Topics ===\n",
      "\n",
      "Topic 1:\n",
      "data, big, business, helps, analytics\n",
      "\n",
      "Topic 2:\n",
      "learning, data, machine, massive, algorithms\n",
      "\n",
      "Topic 3:\n",
      "machines, allows, learning, human, understand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“š Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# ðŸ“¦ Download stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ðŸ”¥ Step 1: Preprocessing (simple and robust)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "processed_docs = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# ðŸ”¥ Step 2: Create Document-Term Matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(processed_docs)\n",
    "\n",
    "# ðŸ”¥ Step 3: Apply LDA\n",
    "lda = LatentDirichletAllocation(n_components=3, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# ðŸ”¥ Step 4: Display Topics\n",
    "def display_topics(model, feature_names, no_top_words=5):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"\\nTopic {topic_idx + 1}:\")\n",
    "        print(\", \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "print(\"\\n=== LDA Topics ===\")\n",
    "display_topics(lda, vectorizer.get_feature_names_out())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3747aa06",
   "metadata": {},
   "source": [
    "Topic 1:\n",
    "Top Words:\n",
    "data, analytics, big, companies, helps\n",
    "\n",
    "ðŸ“– Interpretation:\n",
    "This topic is about Big Data and Analytics.\n",
    "\n",
    "Words like \"big\", \"data\", \"analytics\", \"companies\", \"helps\" suggest:\n",
    "\n",
    "Companies using big data and analytics\n",
    "\n",
    "How analytics helps businesses make better decisions\n",
    "\n",
    "Theme: Business Analytics / Big Data for Decision Support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10420064",
   "metadata": {},
   "source": [
    "Topic 2:\n",
    "Top Words:\n",
    "learning, data, machine, massive, amounts\n",
    "\n",
    "ðŸ“– Interpretation:\n",
    "This topic focuses on Machine Learning processing large data.\n",
    "\n",
    "Words like \"learning\", \"machine\", \"massive\", \"amounts\" suggest:\n",
    "\n",
    "Machine Learning algorithms analyzing huge datasets\n",
    "\n",
    "Handling massive amounts of data through ML techniques\n",
    "\n",
    "Theme: Machine Learning and Big Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b5e2c3",
   "metadata": {},
   "source": [
    "Topic 3:\n",
    "Top Words:\n",
    "allows, machines, learning, human, understand\n",
    "\n",
    "ðŸ“– Interpretation:\n",
    "This topic talks about Machine Learning + Human-like Intelligence.\n",
    "\n",
    "Words like \"machines\", \"learning\", \"human\", \"understand\" suggest:\n",
    "\n",
    "Machines learning to understand humans\n",
    "\n",
    "NLP, Computer Vision â€” areas where machines mimic human behavior\n",
    "\n",
    "Theme: AI Applications â€” Understanding Human Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e933532",
   "metadata": {},
   "source": [
    "Visualization of Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e05f48",
   "metadata": {},
   "source": [
    "pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f6c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“š Imports\n",
    "import pyLDAvis\n",
    "from pyLDAvis import prepare\n",
    "\n",
    "# ðŸ”¥ Step 5: pyLDAvis Visualization (after LDA fit)\n",
    "\n",
    "# Prepare the required inputs\n",
    "doc_topic_distr = lda.transform(X)\n",
    "topic_term_distr = lda.components_ / lda.components_.sum(axis=1)[:, np.newaxis]\n",
    "doc_lengths = X.sum(axis=1).A1\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "term_frequency = np.asarray(X.sum(axis=0)).flatten()\n",
    "\n",
    "# Create pyLDAvis Panel\n",
    "panel = prepare(\n",
    "    topic_term_dists=topic_term_distr,\n",
    "    doc_topic_dists=doc_topic_distr,\n",
    "    doc_lengths=doc_lengths,\n",
    "    vocab=vocab,\n",
    "    term_frequency=term_frequency\n",
    ")\n",
    "\n",
    "# Display inside Jupyter Notebook (if using Jupyter)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(panel)\n",
    "\n",
    "# Or if running outside Notebook (save to HTML and open manually)\n",
    "pyLDAvis.save_html(panel, 'lda_topics_visualization.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ed5a1f",
   "metadata": {},
   "source": [
    "LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c288ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LSA Topics ===\n",
      "\n",
      "Topic 1:\n",
      "learning, allows, machines, human, machine\n",
      "\n",
      "Topic 2:\n",
      "machine, data, learning, algorithms, quickly\n",
      "\n",
      "Topic 3:\n",
      "data, combines, science, domain, programming\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“š Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "# ðŸ”¥ Step 1: Preprocessing (simple lowercase split, consistent with previous)\n",
    "processed_docs = [doc.lower() for doc in documents]\n",
    "\n",
    "# ðŸ”¥ Step 2: Create TF-IDF Matrix\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(processed_docs)\n",
    "\n",
    "# ðŸ”¥ Step 3: Apply LSA using TruncatedSVD\n",
    "lsa = TruncatedSVD(n_components=3, random_state=42)  # 3 topics\n",
    "lsa.fit(X_tfidf)\n",
    "\n",
    "# ðŸ”¥ Step 4: Display Topics\n",
    "def display_lsa_topics(model, feature_names, no_top_words=5):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"\\nTopic {topic_idx + 1}:\")\n",
    "        print(\", \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "print(\"\\n=== LSA Topics ===\")\n",
    "display_lsa_topics(lsa, vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fda3db",
   "metadata": {},
   "source": [
    "Topic 1:\n",
    "Top Words:\n",
    "learning, allows, machines, human, machine\n",
    "\n",
    "ðŸ“– Interpretation:\n",
    "This topic is about Artificial Intelligence mimicking human capabilities.\n",
    "\n",
    "Words like \"machines\", \"human\", \"allows\", and \"learning\" suggest:\n",
    "\n",
    "Enabling machines to learn like humans.\n",
    "\n",
    "Deep Learning, Computer Vision, Natural Language Processing concepts.\n",
    "\n",
    "âœ… Theme:\n",
    "Machines learning to understand humans (AI/Deep Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ecd0b",
   "metadata": {},
   "source": [
    "Topic 2:\n",
    "Top Words:\n",
    "machine, data, learning, algorithms, massive\n",
    "\n",
    "ðŸ“– Interpretation:\n",
    "This topic talks about Machine Learning applied to Big Data.\n",
    "\n",
    "Words like \"machine\", \"data\", \"massive\", \"algorithms\" suggest:\n",
    "\n",
    "ML models analyzing large-scale datasets.\n",
    "\n",
    "Topics like Scalability, Big Data ML, Data Mining.\n",
    "\n",
    "âœ… Theme:\n",
    "Machine Learning for Big Data Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e53f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic 3:\n",
    "Top Words:\n",
    "data, science, programming, domain, expertise\n",
    "\n",
    "ðŸ“– Interpretation:\n",
    "This topic is focused on Data Science as a discipline.\n",
    "\n",
    "Words like \"science\", \"programming\", \"domain\", \"expertise\" suggest:\n",
    "\n",
    "Importance of Domain Knowledge + Coding Skills in data science.\n",
    "\n",
    "âœ… Theme:\n",
    "Data Science: Programming, Domain Expertise, and Application"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-abinitio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
